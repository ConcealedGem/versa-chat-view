import * as mammoth from 'mammoth'
import * as XLSX from 'xlsx'
import { BaseFileParser, type ParsedContent, type ParseOptions } from './base-file-parser'

// Excelè§£æå™¨
export class ExcelParser extends BaseFileParser {
  readonly supportedTypes = ['xlsx', 'xls', 'csv']
  readonly mimeTypes = ['application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'application/vnd.ms-excel']

  async parse(file: File, options?: ParseOptions): Promise<ParsedContent> {
    const arrayBuffer = await this.readAsArrayBuffer(file)
    const fileInfo = this.getFileInfo(file)
    
    const workbook = XLSX.read(new Uint8Array(arrayBuffer), { type: 'array' })
    
    const maxSheets = options?.maxPages || 10
    const sheets = workbook.SheetNames.slice(0, maxSheets).map(sheetName => {
      const worksheet = workbook.Sheets[sheetName]
      const jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1 }) as (string | number)[][]
      
      // é™åˆ¶åªè§£æå‰20è¡Œ
      const limitedData = jsonData.length > 50 ? jsonData.slice(0, 50) : jsonData
      
      return {
        name: sheetName,
        data: limitedData.length > 0 ? limitedData : [['æš‚æ— æ•°æ®']],
        rowCount: jsonData.length, // ä¿æŒåŸå§‹è¡Œæ•°ç”¨äºæ˜¾ç¤º
        displayedRowCount: limitedData.length, // å®é™…æ˜¾ç¤ºçš„è¡Œæ•°
        colCount: limitedData[0]?.length || 0,
        range: worksheet['!ref'] || 'A1',
        isLimited: jsonData.length > 50 // æ ‡è®°æ˜¯å¦è¢«é™åˆ¶
      }
    })

    return {
      type: 'excel',
      fileName: fileInfo.name,
      totalPages: 1,
      content: {
        sheets,
        activeSheet: 0,
        workbookInfo: {
          sheetCount: workbook.SheetNames.length,
          sheetNames: workbook.SheetNames
        }
      },
      metadata: {
        size: fileInfo.size,
        sheetCount: workbook.SheetNames.length,
        lastModified: fileInfo.lastModified
      }
    }
  }
}

// Wordè§£æå™¨
export class WordParser extends BaseFileParser {
  readonly supportedTypes = ['docx', 'doc']
  readonly mimeTypes = ['application/vnd.openxmlformats-officedocument.wordprocessingml.document']

  async parse(file: File, options?: ParseOptions): Promise<ParsedContent> {
    const arrayBuffer = await this.readAsArrayBuffer(file)
    const fileInfo = this.getFileInfo(file)
    
    const htmlResult = await mammoth.convertToHtml({ arrayBuffer })
    const textResult = await mammoth.extractRawText({ arrayBuffer })
    
    // ç®€å•çš„æ®µè½åˆ†é¡µ
    const paragraphs = textResult.value.split('\n\n').filter(p => p.trim())
    const pageSize = 3 // æ¯é¡µ3ä¸ªæ®µè½
    const pages = []
    
    for (let i = 0; i < paragraphs.length; i += pageSize) {
      const pageContent = paragraphs.slice(i, i + pageSize).join('\n\n')
      pages.push({
        pageNumber: Math.floor(i / pageSize) + 1,
        content: pageContent,
        htmlContent: this.extractPageHtml(htmlResult.value, i, pageSize)
      })
    }

    return {
      type: 'word',
      fileName: fileInfo.name,
      totalPages: Math.max(1, pages.length),
      content: {
        htmlContent: htmlResult.value,
        plainText: textResult.value,
        pages: options?.maxPages ? pages.slice(0, options.maxPages) : pages,
        wordCount: textResult.value.split(/\s+/).length,
        paragraphCount: paragraphs.length
      },
      metadata: {
        size: fileInfo.size,
        wordCount: textResult.value.split(/\s+/).length,
        messages: htmlResult.messages || []
      }
    }
  }

  private extractPageHtml(fullHtml: string, startIndex: number, pageSize: number): string {
    // ç®€åŒ–çš„HTMLåˆ†é¡µé€»è¾‘
    const paragraphRegex = /<p[^>]*>.*?<\/p>/g
    const paragraphs = []
    let match
    while ((match = paragraphRegex.exec(fullHtml)) !== null) {
      paragraphs.push(match[0])
    }
    const pageParagraphs = paragraphs.slice(startIndex, startIndex + pageSize)
    return pageParagraphs.join('')
  }
}

// PDFè§£æå™¨
export class PdfParser extends BaseFileParser {
  readonly supportedTypes = ['pdf']
  readonly mimeTypes = ['application/pdf']

  async parse(file: File, options?: ParseOptions): Promise<ParsedContent> {
    const fileInfo = this.getFileInfo(file)
    
    try {
      const pdfjsLib = await import('pdfjs-dist')
      
      if (typeof window !== 'undefined') {
        // ä½¿ç”¨jsDelivr CDNï¼Œæ”¯æŒCORS
        pdfjsLib.GlobalWorkerOptions.workerSrc = `https://cdn.jsdelivr.net/npm/pdfjs-dist@${pdfjsLib.version}/build/pdf.worker.min.mjs`
      }

      const arrayBuffer = await this.readAsArrayBuffer(file)
      const pdf = await pdfjsLib.getDocument({ data: new Uint8Array(arrayBuffer) }).promise
      
      const maxPages = options?.maxPages || 5
      const pages = []
      
      for (let pageNum = 1; pageNum <= Math.min(pdf.numPages, maxPages); pageNum++) {
        const page = await pdf.getPage(pageNum)
        const textContent = await page.getTextContent()
        
        // æ”¹è¿›çš„æ–‡æœ¬æå–é€»è¾‘
        const textItems: string[] = []
        textContent.items.forEach((item) => {
          // æ£€æŸ¥itemçš„ç»“æ„
          if (typeof item === 'object' && item !== null) {
            // å°è¯•å¤šç§å¯èƒ½çš„æ–‡æœ¬å­—æ®µ
            const itemObj = item as Record<string, unknown>
            const text = itemObj.str || itemObj.text || itemObj.content || ''
            if (text && typeof text === 'string' && text.trim()) {
              textItems.push(text.trim())
            }
          }
        })
        
        const text = textItems.join(' ').trim()

        // ä¸ºæ‰«æä»¶æä¾›å‹å¥½æç¤º
        let displayText = text
        if (text.length === 0 && textContent.items.length === 0) {
          displayText = `ğŸ“„ ç¬¬${pageNum}é¡µï¼ˆæ‰«æä»¶ï¼‰

è¿™æ˜¯ä¸€ä¸ªå›¾åƒæ‰«æçš„PDFé¡µé¢ï¼Œæ— æ³•æå–æ–‡æœ¬å†…å®¹ã€‚

å¯èƒ½çš„åŸå› ï¼š
â€¢ é¡µé¢æ˜¯æ‰«æçš„å›¾ç‰‡æ ¼å¼
â€¢ é¡µé¢æ²¡æœ‰å¯é€‰æ‹©çš„æ–‡æœ¬
â€¢ é¡µé¢æ˜¯çº¯å›¾åƒå†…å®¹

å¦‚éœ€æŸ¥çœ‹å†…å®¹ï¼Œå»ºè®®ï¼š
â€¢ ä½¿ç”¨ä¸“é—¨çš„PDFé˜…è¯»å™¨æŸ¥çœ‹
â€¢ ä½¿ç”¨OCRå·¥å…·æå–å›¾åƒä¸­çš„æ–‡å­—
â€¢ æˆ–è€…è·å–åŸæ–‡æ¡£çš„æ–‡æœ¬ç‰ˆæœ¬`
        } else if (text.length === 0) {
          displayText = `ğŸ“„ ç¬¬${pageNum}é¡µ

æœ¬é¡µé¢æ²¡æœ‰æ£€æµ‹åˆ°æ–‡æœ¬å†…å®¹ï¼Œå¯èƒ½æ˜¯ï¼š
â€¢ ç©ºç™½é¡µé¢
â€¢ çº¯å›¾åƒé¡µé¢
â€¢ ç‰¹æ®Šæ ¼å¼é¡µé¢`
        }

        pages.push({
          pageNumber: pageNum,
          text: displayText,
          hasText: text.length > 0,
          itemCount: textContent.items.length, // æ·»åŠ è°ƒè¯•ä¿¡æ¯
          extractedItems: textItems.length,
          isScanned: textContent.items.length === 0 && text.length === 0
        })
      }

      // æ£€æµ‹æ˜¯å¦ä¸ºæ‰«æä»¶
      const scannedPages = pages.filter(page => page.isScanned).length
      const isFullyScanned = scannedPages === pages.length && pages.length > 0

      return {
        type: 'pdf',
        fileName: fileInfo.name,
        totalPages: pdf.numPages,
        content: {
          pages,
          documentInfo: {
            numPages: pdf.numPages,
            fingerprint: pdf.fingerprints?.[0] || '',
            loadTime: Date.now(),
            isScanned: isFullyScanned,
            scannedPages,
            textPagesCount: pages.length - scannedPages
          }
        },
        metadata: {
          size: fileInfo.size,
          numPages: pdf.numPages,
          pagesLoaded: pages.length,
          isScanned: isFullyScanned,
          hasTextContent: pages.some(page => page.hasText)
        }
      }
    } catch (error) {
      console.error('PDFè§£æå¤±è´¥:', error)
      // è¿”å›é”™è¯¯ä¿¡æ¯ä½œä¸ºå†…å®¹
      return {
        type: 'pdf',
        fileName: fileInfo.name,
        totalPages: 1,
        content: {
          pages: [{
            pageNumber: 1,
            text: `PDFè§£æå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}\n\næ–‡ä»¶ä¿¡æ¯:\n- æ–‡ä»¶å: ${fileInfo.name}\n- å¤§å°: ${(fileInfo.size / 1024).toFixed(2)} KB`,
            hasText: true,
            error: true
          }]
        },
        metadata: {
          size: fileInfo.size,
          error: error instanceof Error ? error.message : 'è§£æå¤±è´¥'
        }
      }
    }
  }
} 